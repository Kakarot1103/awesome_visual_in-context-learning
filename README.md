# 
<h1 align='center'>
  <br>
  Awesome_Visual_In-Context-Learning
  <br>
</h1>

<h4 align="center">
  A curated list of classic awesome visual in-context learning methods.
</h4>

<div align="center">
  <a href="https://github.com/sindresorhus/awesome" target='_blank'>
    <img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg">
  </a> &nbsp;&nbsp;&nbsp;
  <a href="https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity" target='_blank'>
    <img src="https://img.shields.io/badge/Maintained%3F-yes-green.svg">
  </a> &nbsp;&nbsp;&nbsp;
  <a href="http://makeapullrequest.com" target='_blank'>
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg">
  </a>
</div>



## Papers

- **Visual Prompting via Image Inpainting,** NeurIPS 2022.
  
  *Amir Bar, Yossi Gandelsman, Trevor Darrell, Amir Globerson, Alexei A Efros.*

  [[Paper](https://openreview.net/forum?id=o4uFFg9_TpV)][[Code](https://yossigandelsman.github.io/visual_prompt/)]


- **Images Speak in Images: A Generalist Painter for In-Context Visual Learning** CVRP 2023.
  
  *Xinlong Wang, Wen Wang, Yue Cao, Chunhua Shen, Tiejun Huang*

  [[Paper](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Images_Speak_in_Images_A_Generalist_Painter_for_In-Context_Visual_CVPR_2023_paper.pdf)][[Code](https://github.com/baaivision/Painter)]

- **SegGPT: Towards Segmenting Everything In Context** ICCV 2023
- 
   *Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, Tiejun Huang*
  
  [[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_SegGPT_Towards_Segmenting_Everything_in_Context_ICCV_2023_paper.pdf)][[code](https://github.com/baaivision/Painter)]

- **In-Context Learning Unlocked for Diffusion Models** NeurIPS 2023

  *Zhendong Wang, Yifan Jiang, Yadong Lu, Yelong Shen, Pengcheng He, Weizhu Chen, Zhangyang Wang, Mingyuan Zhou*
  
  [[paper](https://arxiv.org/pdf/2305.01115v1.pdf)][[code](https://github.com/Zhendong-Wang/Prompt-Diffusion)]

- **ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation** NeurIPS 2023
  
   *Yasheng SUN, Yifan Yang, Houwen Peng, Yifei Shen, Yuqing Yang, Han Hu, Lili Qiu, Hideki Koike*
  
    [[Paper]([https://openreview.net/forum?id=o4uFFg9_TpV](https://arxiv.org/abs/2308.00906))]

- **Visual Instruction Inversion: Image Editing via Visual Prompting** NeurIPS 2023

  *Thao Nguyen, Yuheng Li, Utkarsh Ojha, Yong Jae Lee*

  [[paper](https://arxiv.org/abs/2307.14331)][[code](https://thaoshibe.github.io/visii/)]

- **Visual In-Context Prompting** Arvix 2023.11

  *Feng Li, Qing Jiang, Hao Zhang, Tianhe Ren, Shilong Liu, Xueyan Zou, Huaizhe Xu, Hongyang Li, Chunyuan Li, Jianwei Yang, Lei Zhang, Jianfeng Gao*

  [[paper](https://arxiv.org/pdf/2311.13601.pdf)][[code](https://github.com/UX-Decoder/DINOv)]

- **T-Rex: Counting by Visual Prompting** Arvix 2023.11

  *Qing Jiang, Feng Li, Tianhe Ren, Shilong Liu, Zhaoyang Zeng, Kent Yu, Lei Zhang*

  [[paper](https://arxiv.org/abs/2311.13596)][[code](https://trex-counting.github.io/)]

- **Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts** Arvix 2023.12

  *Tianqi Chen, Yongfei Liu, Zhendong Wang, Jianbo Yuan, Quanzeng You, Hongxia Yang, Mingyuan Zhou*

  [[paper](https://arxiv.org/pdf/2312.01408.pdf)]

## Related paper

- **All in Tokens: Unifying Output Space of Visual Tasks via Soft Token**
  
  *Jia Ning, Chen Li, Zheng Zhang, Zigang Geng, Qi Dai, Kun He, Han Hu*

  [[paper](https://arxiv.org/pdf/2301.02229v2.pdf)][[code](https://github.com/SwinTransformer/AiT)]

- **GlyphControl: Glyph Conditional Control for Visual Text Generation**

  *Yukang Yang， Dongnan Gui， Yuhui Yuan， Weicong Liang， Haisong Ding， Han Hu， Kai Chen*

  [[paper](https://openreview.net/pdf?id=thPI8hrA4V)][[code](https://github.com/AIGText/GlyphControl-release)]
  
- **Exploring Diverse In-Context Configurations for Image Captioning**
  
  *Xu Yang1, Yongliang Wu, Mingzhuo Yang, Haokun Chen, Xin Geng*

  [[paper](https://arxiv.org/pdf/2305.14800.pdf)][[code](https://github.com/yongliang-wu/ExploreCfg)]
  
- **Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering**
  
 *Zhenwei Shao, Zhou Yu, Meng Wang, Jun Yu*

 [[paper](https://arxiv.org/pdf/2303.01903.pdf)][[code](https://github.com/MILVLG/prophet)]
